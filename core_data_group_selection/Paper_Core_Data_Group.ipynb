{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import chain\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load phenotypes for GWAS sample\n",
    "phenostructure = pd.read_csv('/psych/genetics_data/ccarey/UKBB/ukb_files/Data_Dictionary_Showcase.csv',index_col=\"FieldID\")\n",
    "phenos = pd.read_table('/stanley/genetics/analysis/ukbb_sexdiff/family_based/ukb31063_fullsample_phesant_icd10_phenotypes_bothsexes.tsv',dtype=object,index_col=\"userId\")\n",
    "sample = pd.read_table('/psych/genetics_data/ccarey/UKBB/ukb_files/ukb_whitebritish.txt',sep=\" \",index_col=\"IID\")\n",
    "phenos = phenos.loc[np.intersect1d(sample.index,phenos.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get shape of phenotype matrix\n",
    "phenos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get null-nonnull matrix\n",
    "phenos_notnull=phenos.notnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep one column for each cat-mult\n",
    "phenos_notnull_nodupes = phenos_notnull.loc[:,~phenos_notnull.columns.str.split('_').str[0].duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot sample-level completeness\n",
    "plt.hist(phenos_notnull_nodupes.apply(np.mean,axis=1),bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot item-level N's\n",
    "plt.hist(phenos_notnull_nodupes.apply(sum,axis=0),bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transpose df to index on items/phenos\n",
    "phenos_notnull_nodupes_itemindexed = phenos_notnull_nodupes.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add path column to df\n",
    "phenos_notnull_nodupes_itemindexed['path'] = phenostructure.loc[phenos_notnull_nodupes_itemindexed.index.str.split('_').str[0].values.astype(int)].Path.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create questionnaire dict\n",
    "category_dict = phenos_notnull_nodupes_itemindexed.reset_index().groupby('path')['index'].apply(list).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize unit/questionnaire completeness df\n",
    "unit_completeness = pd.DataFrame(columns=category_dict.keys(),index=phenos_notnull_nodupes.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize dict of items per questionnaire\n",
    "item_ns = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine whether each individual attempted a questionnaire\n",
    "# also create dict of items per questionnaire\n",
    "for key in category_dict.keys():\n",
    "    item_ns[key]=len(category_dict[key])\n",
    "    unit_completeness[key] = phenos_notnull_nodupes[category_dict[key]].apply(np.any,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize individual \"attempt\" correlations across questionnaires\n",
    "f, ax = plt.subplots(figsize=(15, 15))\n",
    "sns.set(font_scale=0.75)\n",
    "ax = sns.heatmap(unit_completeness.corr(),square=True, cbar_kws={\"shrink\": 0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy completeness df\n",
    "unit_completeness_merge = unit_completeness.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dict of lowest-level categories and their parent categories\n",
    "mykeys = list(unit_completeness_merge.columns.str.rsplit(\">\",1).str[0].str.strip())\n",
    "myvals = list(unit_completeness_merge.columns)\n",
    "d = dict()\n",
    "for i in range(len(mykeys)):\n",
    "    if(mykeys[i] in d.keys()):\n",
    "        d[mykeys[i]].append(myvals[i])\n",
    "    else:\n",
    "        d[mykeys[i]] = [myvals[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each parent category, see if can merge some lowest-level categories with high cross-questionnaire correlations\n",
    "for key in d.keys():\n",
    "\n",
    "    if len(d[key])>1:\n",
    "        tempcorr = unit_completeness[d[key]].corr()\n",
    "        indices = np.where(tempcorr > 0.95)\n",
    "        indices = [(tempcorr.index[x], tempcorr.columns[y]) for x, y in zip(*indices)\n",
    "                                        if x != y and x < y]\n",
    "        if len(indices)>0:\n",
    "            # create dict of highly correlated questionnaires\n",
    "            tempd = dict()\n",
    "            for x,y in indices:\n",
    "                if(x in tempd.keys()):\n",
    "                    tempd[x].append(y)\n",
    "                elif(x in list(set(chain(*tempd.values())))):\n",
    "                    pass\n",
    "                else:\n",
    "                    tempd[x] = [y]\n",
    "\n",
    "            # merge highly correlated questionnaires\n",
    "            counter = 1\n",
    "            for tempkey in tempd.keys():\n",
    "                addlist = tempd[tempkey]\n",
    "                addlist.append(tempkey)\n",
    "                newcol = \" > \".join([key,\"Group_\"+str(counter)])\n",
    "                print(newcol,addlist)\n",
    "                unit_completeness_merge[newcol] = unit_completeness_merge.loc[:,addlist].apply(lambda x: np.any(x),axis=1)\n",
    "                unit_completeness_merge.drop(addlist, inplace=True,axis=1)\n",
    "                item_ns[newcol] = sum([item_ns[x] for x in addlist])\n",
    "                for item in addlist:\n",
    "                    item_ns.pop(item)\n",
    "                counter = counter+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize individual \"attempt\" correlations across merged questionnaires\n",
    "f, ax = plt.subplots(figsize=(15, 15))\n",
    "sns.set(font_scale=0.75)\n",
    "ax = sns.heatmap(unit_completeness_merge.corr(),square=True, cbar_kws={\"shrink\": 0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot questonnaire completeness per individual\n",
    "plt.hist(unit_completeness_merge.apply(sum,axis=1),bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot questionnaire N's\n",
    "plt.hist(unit_completeness_merge.apply(sum,axis=0),bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SPECIFY FILTERING PARAMS\n",
    "Nmin = 75000\n",
    "Nmax = 250000\n",
    "Nitems = 5\n",
    "nmar_and_sexspecific = ['UK Biobank Assessment Centre > Touchscreen > Sex-specific factors > Female-specific factors','Health-related outcomes > Cancer register','Health-related outcomes > Death register','Health-related outcomes > Hospital in-patient > Maternity > Summary Information (maternity)']\n",
    "Qmiss = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only consider questionnaires completed by between Nmin and Nmax people\n",
    "unit_completeness_merge_Nmin_Nmax = unit_completeness_merge.loc[:,(unit_completeness_merge.apply(sum,axis=0)>Nmin) & (unit_completeness_merge.apply(sum,axis=0)<Nmax)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove questionnaires consisting of less than Nitems items\n",
    "unit_completeness_merge_Nmin_Nmax_Nitems = unit_completeness_merge_Nmin_Nmax.loc[:,[item_ns[x] >= Nitems for x in unit_completeness_merge_Nmin_Nmax.columns.values]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop sex-specific and MNAR questionnaires\n",
    "unit_completeness_merge_Nmin_Nmax_Nitems_dropped = unit_completeness_merge_Nmin_Nmax_Nitems.drop(np.intersect1d(nmar_and_sexspecific,unit_completeness_merge_Nmin_Nmax_Nitems.columns.values),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize individual \"attempt\" correlations across merged questionnaires\n",
    "f, ax = plt.subplots(figsize=(15, 15))\n",
    "ax = sns.heatmap(unit_completeness_merge_Nmin_Nmax_Nitems_dropped.corr(),square=True, cbar_kws={\"shrink\": 0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get questionnaire-level completeness patterns and their frequencies\n",
    "missingness_patterns = unit_completeness_merge_Nmin_Nmax_Nitems_dropped.groupby(list(unit_completeness_merge_Nmin_Nmax_Nitems_dropped.columns), as_index=False).size().reset_index().rename(columns={0:\"N\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate number of questionnaires included in each pattern\n",
    "missingness_patterns[\"n_questionnaires\"] = missingness_patterns.iloc[:,:-1].apply(sum,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort completeness pattern dataframe by number of questionnaires, then N per pattern\n",
    "missingness_patterns_toplot = missingness_patterns.sort_values([\"n_questionnaires\",\"N\"],ascending=[False,False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define x-labels to be n_questionnaires plus N individuals\n",
    "xlabs = missingness_patterns_toplot.apply(lambda x: \"_\".join([str(x.n_questionnaires),str(x.N)]),axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define y-labels to be the category/path, plus N individuals, plus n_items\n",
    "ylabs = [\", N=\".join([x,y,z]) for x,y,z in zip(unit_completeness_merge_Nmin_Nmax_Nitems_dropped.columns.values, unit_completeness_merge_Nmin_Nmax_Nitems_dropped.apply(sum,axis=0).astype(str).values,[str(item_ns[x]) for x in unit_completeness_merge_Nmin_Nmax_Nitems_dropped.columns.values])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot completeness patterns\n",
    "f, ax = plt.subplots(figsize=(70, 70))\n",
    "sns.heatmap(~missingness_patterns_toplot.iloc[:,:-2].astype(int).T,square=True,cbar=False, xticklabels=xlabs,yticklabels=ylabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot questonnaire completeness per individual\n",
    "qhist = plt.hist(unit_completeness_merge_Nmin_Nmax_Nitems_dropped.apply(sum,axis=1),bins=missingness_patterns_toplot.iloc[:,:-2].shape[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qhist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qhist[0][len(qhist[0])-Qmiss:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of individuals missing Qmiss questionnaires or less\n",
    "inds_Qmiss = unit_completeness_merge_Nmin_Nmax_Nitems_dropped[unit_completeness_merge_Nmin_Nmax_Nitems_dropped.apply(sum,axis=1)>=(len(qhist[0])-Qmiss)].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset original phenotype file to \"core\" individuals\n",
    "phenos_Qmiss = phenos.loc[inds_Qmiss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenos_Qmiss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get null-nonnull matrix\n",
    "phenos_Qmiss_notnull=phenos_Qmiss.notnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove items that are mnar or sex-specific\n",
    "remove_cats = [category_dict[x] for x in nmar_and_sexspecific]\n",
    "flat_remove_cats = [val for sublist in remove_cats for val in sublist]\n",
    "phenos_Qmiss_notnull_removed = phenos_Qmiss_notnull.drop(flat_remove_cats,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load phenosummary file\n",
    "phenosummary = pd.read_table('/stanley/genetics/analysis/ukbb_sexdiff/family_based/ukb31063_gwas_phesant_icd10_phenotypes_summary.tsv',dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset to the both-sexes row of all phenotypes\n",
    "phenosummary_bothsexes = phenosummary[phenosummary.sex==\"both\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenos_Qmiss_notnull_removed_bothsexes = phenos_Qmiss_notnull_removed.loc[:,np.intersect1d(phenos_Qmiss_notnull_removed.columns.values,phenosummary_bothsexes.id.values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2772-phenos_Qmiss_notnull_removed_bothsexes.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transpose df to index on items/phenos\n",
    "phenos_Qmiss_notnull_removed_bothsexes_itemindexed = phenos_Qmiss_notnull_removed_bothsexes.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add Ns to items\n",
    "phenos_Qmiss_notnull_removed_bothsexes_itemindexed['N']=phenos_Qmiss_notnull_removed_bothsexes_itemindexed.apply(sum,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add path column to df\n",
    "phenos_Qmiss_notnull_removed_bothsexes_itemindexed['name'] = phenostructure.loc[phenos_Qmiss_notnull_removed_bothsexes_itemindexed.index.str.split('_').str[0].values.astype(int)].Field.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all phenotypes N<30k\n",
    "phenos_Qmiss_notnull_removed_bothsexes_itemindexed_minN = phenos_Qmiss_notnull_removed_bothsexes_itemindexed[phenos_Qmiss_notnull_removed_bothsexes_itemindexed.N>=30000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenos_Qmiss_notnull_removed_bothsexes_itemindexed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenos_Qmiss_notnull_removed_bothsexes_itemindexed_minN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenos_inds_items = phenos_Qmiss_notnull_removed_bothsexes_itemindexed_minN.copy().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenos_inds_items = phenos_inds_items.drop([\"N\",\"name\"],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset to binary phenotypes\n",
    "phenosummary_bothsexes_binary = phenosummary_bothsexes[~pd.isnull(phenosummary_bothsexes.GWAS_n_cases)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate Neff \n",
    "phenosummary_bothsexes_binary['Neff'] = phenosummary_bothsexes_binary.apply(lambda x: float(4)/((1.0/int(x.GWAS_n_cases))+(1.0/int(x.GWAS_n_controls))),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate GWAS prevalence \n",
    "phenosummary_bothsexes_binary['prevalence'] = phenosummary_bothsexes_binary.apply(lambda x: float(x.GWAS_n_cases)/float(x.GWAS_n_nonmiss),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenosummary_bothsexes_binary[phenosummary_bothsexes_binary.id==\"1767\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1-0.01431"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset to phenotypes with prevalence >=1% in GWAS sample\n",
    "phenosummary_underPrev = phenosummary_bothsexes_binary[(phenosummary_bothsexes_binary.prevalence<0.01) | (phenosummary_bothsexes_binary.prevalence>0.99)].id.values\n",
    "phenos_inds_items_bothsexes_prev = phenos_inds_items.drop(np.intersect1d(phenos_inds_items.columns.values,phenosummary_underPrev),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenos_inds_items_bothsexes_prev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampprev(x):\n",
    "    #print(x.name)\n",
    "    if x.name in phenosummary_bothsexes_binary.id.values:\n",
    "        if x.sum()==42325:\n",
    "            return True\n",
    "        else:\n",
    "            #print((float(x.value_counts()[1])/x.value_counts().sum()))\n",
    "            print(x.value_counts())\n",
    "            print((float(x.value_counts()[1])/x.value_counts().sum()))\n",
    "            return ((float(x.value_counts()[1])/x.value_counts().sum()))<0.99\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenos_inds_items_bothsexes_prev.apply(lambda x: sampprev(x)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset to phenotypes with prevalence >=1% in core sample\n",
    "\n",
    "def sampprev(x):\n",
    "    #print(x.name)\n",
    "    if x.name in phenosummary_bothsexes_binary.id.values:\n",
    "        if x.sum()==42325:\n",
    "            return True\n",
    "        else:\n",
    "            return ((float(x.value_counts()[1])/x.value_counts().sum()))<0.99\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "phenos_inds_items_bothsexes_prev_sampprev = phenos_inds_items_bothsexes_prev.loc[:,phenos_inds_items_bothsexes_prev.apply(lambda x: sampprev(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = phenos_inds_items_bothsexes_prev_sampprev.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenos_inds_items_bothsexes_prev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset original phenotype file to \"core\" individuals\n",
    "phenos_Qmiss = phenos.loc[inds_Qmiss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get null-nonnull matrix\n",
    "phenos_Qmiss_notnull=phenos_Qmiss.notnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove items that are mnar or sex-specific\n",
    "remove_cats = [category_dict[x] for x in nmar_and_sexspecific]\n",
    "flat_remove_cats = [val for sublist in remove_cats for val in sublist]\n",
    "phenos_Qmiss_notnull_removed = phenos_Qmiss_notnull.drop(flat_remove_cats,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep one column for each cat-mult\n",
    "phenos_Qmiss_notnull_removed_nodupes = phenos_Qmiss_notnull_removed.loc[:,~phenos_Qmiss_notnull_removed.columns.str.split('_').str[0].duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transpose df to index on items/phenos\n",
    "phenos_Qmiss_notnull_removed_nodupes_itemindexed = phenos_Qmiss_notnull_removed_nodupes.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add Ns to items\n",
    "phenos_Qmiss_notnull_removed_nodupes_itemindexed['N']=phenos_Qmiss_notnull_removed_nodupes_itemindexed.apply(sum,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add path column to df\n",
    "phenos_Qmiss_notnull_removed_nodupes_itemindexed['name'] = phenostructure.loc[phenos_Qmiss_notnull_removed_nodupes_itemindexed.index.str.split('_').str[0].values.astype(int)].Field.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all phenotypes N<30k\n",
    "phenos_Qmiss_notnull_removed_nodupes_itemindexed_minN = phenos_Qmiss_notnull_removed_nodupes_itemindexed[phenos_Qmiss_notnull_removed_nodupes_itemindexed.N>=30000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reintroduce all cat-mult dummies\n",
    "phenos_inds_items = phenos.loc[inds_Qmiss, list(np.apply_along_axis(np.any,0,np.array([phenos.columns.str.split(\"_\").str[0]==(x.split(\"_\")[0]) for x in phenos_Qmiss_notnull_removed_nodupes_itemindexed_minN.index.values])))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load phenosummary file\n",
    "phenosummary = pd.read_table('/stanley/genetics/analysis/ukbb_sexdiff/family_based/ukb31063_gwas_phesant_icd10_phenotypes_summary.tsv',dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset to the both-sexes row of all phenotypes\n",
    "phenosummary_bothsexes = phenosummary[phenosummary.sex==\"both\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset to binary phenotypes\n",
    "phenosummary_bothsexes_binary = phenosummary_bothsexes[~pd.isnull(phenosummary_bothsexes.GWAS_n_cases)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate Neff \n",
    "phenosummary_bothsexes_binary['Neff'] = phenosummary_bothsexes_binary.apply(lambda x: float(4)/((1.0/int(x.GWAS_n_cases))+(1.0/int(x.GWAS_n_controls))),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate GWAS prevalence \n",
    "phenosummary_bothsexes_binary['prevalence'] = phenosummary_bothsexes_binary.apply(lambda x: float(x.GWAS_n_cases)/float(x.GWAS_n_nonmiss),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"manually\" remove phenotypes not applicable to both sexes\n",
    "phenos_inds_items_bothsexes = phenos_inds_items.loc[:,np.intersect1d(phenos_inds_items.columns.values,phenosummary_bothsexes.id.values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenos_inds_items_bothsexes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset to phenotypes with prevalence >=1% in GWAS sample\n",
    "phenosummary_underPrev = phenosummary_bothsexes_binary[(phenosummary_bothsexes_binary.prevalence<0.01) | (phenosummary_bothsexes_binary.prevalence>0.99)].id.values\n",
    "phenos_inds_items_bothsexes_prev = phenos_inds_items_bothsexes.drop(np.intersect1d(phenos_inds_items_bothsexes.columns.values,phenosummary_underPrev),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenos_inds_items_bothsexes_prev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset to phenotypes with prevalence >=1% in core sample\n",
    "\n",
    "def sampprev(x):\n",
    "    if x.name in phenosummary_bothsexes_binary.id.values:\n",
    "        return ((float(x.value_counts()[0])/x.value_counts().sum()))<0.99\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "phenos_inds_items_bothsexes_prev_sampprev = phenos_inds_items_bothsexes_prev.loc[:,phenos_inds_items_bothsexes_prev.apply(lambda x: sampprev(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old = phenos_inds_items_bothsexes_prev_sampprev.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.setdiff1d(new,old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_dependencies = phenos_inds_items_bothsexes_prev_sampprev.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    corrmat = remove_dependencies.astype(float).corr()\n",
    "    display(corrmat.shape)\n",
    "    \n",
    "    indices = np.where(np.isnan(corrmat))\n",
    "    \n",
    "    if len(indices[0])==0:\n",
    "        break\n",
    "    \n",
    "    indices = [(corrmat.index[x], corrmat.columns[y]) for x, y in zip(*indices)]\n",
    "               #if x != y and x < y]\n",
    "    tempd = dict()\n",
    "    for y,x in indices:\n",
    "        if(y in tempd.keys()):\n",
    "            tempd[y].append(x)\n",
    "        #elif(y in list(set(chain(*tempd.values())))):\n",
    "        #    pass\n",
    "        else:\n",
    "            tempd[y] = [x]\n",
    "            \n",
    "    keypairs = pd.DataFrame(columns=['values','len','prev','sampprev',\"n_case\",'std'],index=tempd.keys())\n",
    "    \n",
    "    for key in tempd.keys():\n",
    "        keypairs.loc[key,'values'] = tempd[key]\n",
    "        keypairs.loc[key,'len'] = len(tempd[key])\n",
    "        try:\n",
    "            keypairs.loc[key,'prev'] = phenosummary_bothsexes_binary.set_index('id').loc[str(key)].prevalence\n",
    "            keypairs.loc[key,'sampprev'] = float(remove_dependencies[key].value_counts()[0])/remove_dependencies[key].value_counts().sum()\n",
    "            keypairs.loc[key,'n_case'] = remove_dependencies[key].value_counts()[1]\n",
    "        except:\n",
    "            keypairs.loc[key,'std'] = np.std(remove_dependencies[key].astype(float))\n",
    "    \n",
    "    display(keypairs.sort_values(['len','sampprev','std'],ascending=[False,False,True]))\n",
    "    \n",
    "    firstix = keypairs.sort_values(['len','sampprev','std'],ascending=[False,False,True]).index[0]\n",
    "    \n",
    "    remove_dependencies.drop(firstix,axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get null-nonnull matrix\n",
    "remove_dependencies_notnull=remove_dependencies.notnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(remove_dependencies_notnull.apply(np.mean,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep one column for each cat-mult\n",
    "remove_dependencies_notnull_nodupes = remove_dependencies_notnull.loc[:,~remove_dependencies_notnull.columns.str.split('_').str[0].duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot sample-level completeness\n",
    "plt.hist(remove_dependencies_notnull_nodupes.apply(np.mean,axis=1),bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot item-level N's\n",
    "plt.hist(remove_dependencies_notnull_nodupes.apply(sum,axis=0),bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.matrix_rank(np.asmatrix(remove_dependencies.astype(float).corr()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_dependencies.to_csv(\"/psych/genetics_data/ccarey/UKBB/factor_gwas/core_data_group/FA_core.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenonames = pd.DataFrame(columns=['name'], index=remove_dependencies.columns)\n",
    "phenonames['name'] = phenosummary_bothsexes.set_index('id').loc[remove_dependencies.columns].name.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenonames.to_csv(\"/psych/genetics_data/ccarey/UKBB/factor_gwas/core_data_group/FA_core_FieldNames.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_dependencies.apply(phenosummary_bothsexes[phenosummary_bothsexes.id==x].name.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in remove_dependencies:\n",
    "    print(item, phenosummary_bothsexes[phenosummary_bothsexes.id==item].name.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_dependencies.astype(float).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.where(np.isinf(corrmat))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_dependencies.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmat = phenos_inds_items_bothsexes_prev_sampprev.astype(float).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.where(np.isnan(corrmat))\n",
    "indices = [(corrmat.index[x], corrmat.columns[y]) for x, y in zip(*indices)]\n",
    "           #if x != y and x < y]\n",
    "tempd = dict()\n",
    "for y,x in indices:\n",
    "    if(y in tempd.keys()):\n",
    "        tempd[y].append(x)\n",
    "    #elif(y in list(set(chain(*tempd.values())))):\n",
    "    #    pass\n",
    "    else:\n",
    "        tempd[y] = [x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keypairs = pd.DataFrame(columns=['values','len','prev','sampprev',\"n_case\"],index=tempd.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in tempd.keys():\n",
    "    keypairs.loc[key,'values'] = tempd[key]\n",
    "    keypairs.loc[key,'len'] = len(tempd[key])\n",
    "    try:\n",
    "        keypairs.loc[key,'prev'] = phenosummary_bothsexes_binary.set_index('id').loc[str(key)].prevalence\n",
    "        keypairs.loc[key,'sampprev'] = float(phenos_inds_items_bothsexes_prev_sampprev[key].value_counts()[0])/phenos_inds_items_bothsexes_prev_sampprev[key].value_counts().sum()\n",
    "        keypairs.loc[key,'n_case'] = phenos_inds_items_bothsexes_prev_sampprev[key].value_counts()[1]\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keypairs.sort_values(['len','sampprev'],ascending=[False,False]).index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_completeness_merge_Nmin_Nmax_Nitems_dropped['scot_urban'] = phenos.loc[unit_completeness_merge_Nmin_Nmax_Nitems_dropped.index.values,'20118_11']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_completeness_merge_Nmin_Nmax_Nitems_dropped.groupby('scot_urban').sum()\n",
    "#.groupby('scot_urban').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenos['20118_11'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keypairs.sort_values('len',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.where(np.isnan(corrmat))\n",
    "indices = pd.DataFrame([(corrmat.index[x], corrmat.columns[y]) for x, y in zip(*indices) if x != y and x < y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenos_inds_items_bothsexes_prev[['1920', '1930', '1940', '1950', '1960', '1970', '1980', '1990', '2000', '2010', '2020', '2030']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.matrix_rank(np.asmatrix(phenos_inds_items_bothsexes_prev.values.astype(float)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in phenos_inds_items_bothsexes_Prev:\n",
    "    print(item, phenosummary_bothsexes[phenosummary_bothsexes.id==item].name.values[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenos_notnull_nodupes.apply(sum,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
